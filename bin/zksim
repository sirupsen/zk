#!/usr/bin/env python3
import sys
import argparse
import os
import sqlite3

try:
    from sklearn.metrics.pairwise import linear_kernel
    from sklearn.feature_extraction.text import TfidfVectorizer
    import pandas as pd
except ImportError as e:
    print(f"Missing {e.name}! Please run pip3 install scikit-learn pandas")
    exit()


"""
This script takes a zettelkasten note filename and sorts the available notes by their similarity
using Term Frequency-Inverse Document Frequency (TF-IDF). The idea is to use this to help one make
connections in their zettelkasten they may have not thought of initially. 
"""


def vectorize_text(series):
    """
    Uses sklearn text vectorizer. Will do the necessary preprocessing like removing stop words,
    transform to lowercase etc.

    :param series: Pandas Series object
    :return: matrix of tf-idf features
    """
    return TfidfVectorizer().fit_transform(series.values)


def index_from_title(series, title):
    index = series[series == title].index
    if len(index) == 0:
        raise ValueError("Invalid note title! This note title does not exist in your zk.")
    return index


def similarity_index(search_index, vectors):
    """
    Uses cosine similarity to find which documents are the most similar to the file index passed
    in search_index
    :param search_index: Index of file you want similar files to
    :param vectors: Vector of TF-IDF vector features for each document
    :return: Returns the index numbers of the decuments in order of similarity
    """
    cosine_similarities = linear_kernel(vectors[search_index], vectors).flatten()
    return (-cosine_similarities).argsort()


def relevant_titles(df, title, title_col, text_col):
    """
    Uses indexes from similarity_index to sort the DataFrame of notes by similarity
    :param df: DataFame of notes (from zettelkasten database)
    :param title: Title to search for similar files
    :param title_col: Name of column in DataFrame that has titles of each note
    :param text_col: Name of column in DataFrame that has the body of each note
    :return: DataFrame sorted by similarity to the note title passed
    """
    vectors = vectorize_text(df[text_col])
    searching_index = index_from_title(df[title_col], title)
    sim_index = similarity_index(searching_index, vectors)
    return df.iloc[sim_index][title_col].values


class MyParser(argparse.ArgumentParser):
    def error(self, message):
        sys.stderr.write('error: %s\n' % message)
        self.print_help()
        sys.exit(2)


class CustomAction(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        setattr(namespace, self.dest, " ".join(values))


class TfidfSearch:

    def __init__(self):

        if 'ZK_PATH' in os.environ:
            self.zk_path = os.environ['ZK_PATH']
        else:
            raise KeyError("ZK_PATH variable not defined! Run $ echo 'export ZK_PATH=$HOME/Zettelkasten' >> ~/.bashrc")

        self.conn = sqlite3.connect(os.path.join(self.zk_path, "index.db"))
        self.cursor = self.conn.cursor()
        self.num_files_to_show = 20

    def application_logic(self, filename):
        df = pd.read_sql("SELECT * FROM zettelkasten WHERE title NOT LIKE 'highlights/%'", con=self.conn)
        for file in relevant_titles(df, filename, title_col="title", text_col="body")[:self.num_files_to_show]:
            print(file)

    def run(self):
        parser = argparse.ArgumentParser(description='Perform document similarity search based on TF-IDF')
        parser.add_argument('filename', metavar='filename', type=str, nargs='+', action=CustomAction,
                            help='filename to search for similarity')

        if len(sys.argv) == 1:
            parser.print_help(sys.stderr)
            sys.exit(1)

        args = parser.parse_args()
        self.application_logic(args.filename)


if __name__ == "__main__":
    TfidfSearch().run()
